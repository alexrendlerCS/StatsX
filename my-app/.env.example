# NFL Statistics App with AI Integration - Environment Configuration

# Supabase Configuration (Required)
NEXT_PUBLIC_SUPABASE_URL=https://your-project.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=your-anon-key
SUPABASE_SERVICE_ROLE_KEY=your-service-role-key

# OpenAI Configuration (Required for embeddings)
OPENAI_API_KEY=sk-your-openai-api-key

# Ollama Configuration (Optional - for local AI)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# Database Configuration (for Python scripts)
DB_HOST=db.your-project.supabase.co
DB_NAME=postgres
DB_USER=postgres
DB_PASSWORD=your-database-password
DB_PORT=5432

# AI Configuration
AI_PROVIDER=ollama  # Options: 'ollama' | 'openai'
AI_TEMPERATURE=0.7
AI_MAX_TOKENS=1000

# Vector Database Configuration
VECTOR_DIMENSION=1536  # OpenAI embeddings dimension
VECTOR_INDEX_LISTS=100  # HNSW index parameter
VECTOR_PROBES=10       # Search parameter

# Cache Configuration
REDIS_URL=redis://localhost:6379  # Optional: for embedding cache
CACHE_TTL=3600  # Cache time-to-live in seconds

# Development Configuration
NODE_ENV=development
DEBUG_MODE=true
LOG_LEVEL=info

# Setup Instructions:
# 1. Copy this file to .env.local and fill in your actual values
# 2. Install Ollama from https://ollama.ai/
# 3. Run: ollama pull llama3.1:8b (or your preferred model)
# 4. Run: ollama pull nomic-embed-text (for embeddings)
# 5. Start Ollama service: ollama serve
# 6. Run: npm run setup-vectors init (to initialize vector database)
# 7. Run: npm run setup-vectors populate (to populate with NFL data)